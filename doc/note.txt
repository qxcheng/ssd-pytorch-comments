1. 改动
coco.py --> COCO_ROOT
config.py --> HOME

layers/modules/multibox_loss.py  line97 loss
train.py line183 loss
eval.py  line425 cuda
test.py  line89  cuda

2.SSD网络结构
输入：1x3x300x300

[base_]
特征图：(1,3,300,300)
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),            (1,64,300,300)
ReLU(inplace),
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),           (1,64,300,300)
ReLU(inplace),
MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),  (1,64,150,150)

Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),          (1,128,150,150)
ReLU(inplace),
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),         (1,128,150,150)
ReLU(inplace),
MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),  (1,128,75,75)

Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),         (1,256,75,75)
ReLU(inplace),
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),         (1,256,75,75)
ReLU(inplace),
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),         (1,256,75,75)
ReLU(inplace),
MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True),   (1,256,38,38)

Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),         (1,512,38,38)
ReLU(inplace),
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),         (1,512,38,38)
ReLU(inplace),
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),         (1,512,38,38)
ReLU(inplace),                                                               (1,512,38,38) -> L2Norm -> (1,512,38,38)
-----------------------------------------------------------------------------
MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),             (1,512,19,19)

Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),                    (1,512,19,19)
ReLU(inplace),
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),                    (1,512,19,19)
ReLU(inplace),
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),                    (1,512,19,19)
ReLU(inplace),
MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False),             (1,512,19,19)

Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6)),  (1,1024,19,19)
ReLU(inplace),
Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1)),                                  (1,1024,19,19)
ReLU(inplace)                                                                           (1,1024,19,19) -> 直接取此值

[extras_]
Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1)),                                   (1,256,19,19)
ReLU(inplace),
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)),                    (1,512,10,10)
ReLU(inplace),                                                                          (1,512,10,10) -> 直接取此值
Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1)),                                    (1,128,10,10)
ReLU(inplace),
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)),                    (1,256,5,5)
ReLU(inplace),                                                                          (1,256,5,5) -> 直接取此值
Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1)),                                    (1,128,5,5)
ReLU(inplace),
Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1)),                                    (1,256,3,3)
ReLU(inplace),                                                                          (1,256,3,3) -> 直接取此值
Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1)),                                    (1,128,3,3)
ReLU(inplace),
Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))                                     (1,256,1,1)
ReLU(inplace),                                                                          (1,256,1,1) -> 直接取此值


[head_]
[loc]
Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),    (1,512,38,38)  ->permute (1,38,38,16)  -> (1,23104)
Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),   (1,1024,19,19) ->permute (1,19,19,24)  -> (1,8664)
Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),    (1,128,10,10)  ->permute (1,10,10,24)  -> (1,2400)
Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),    (1,128,5,5)    ->permute (1,5,5,24)    -> (1,600)
Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),    (1,128,3,3)    ->permute (1,3,3,16)    -> (1,144)
Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1),     (1,256,1,1)    ->permute (1,1,1,16)    -> (1,16)
拼接为：(1,34928)
[conf]
Conv2d(512, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),    (1,512,38,38)  ->permute (1,38,38,84)  -> (1,121296)
Conv2d(1024, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),  (1,1024,19,19) ->permute (1,19,19,126) -> (1,45486)
Conv2d(512, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),   (1,128,10,10)  ->permute (1,10,10,126) -> (1,12600)
Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),   (1,128,5,5)    ->permute (1,5,5,126)   -> (1,3150)
Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),    (1,128,3,3)    ->permute (1,3,3,84)    -> (1,756)
Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))     (1,256,1,1)    ->permute (1,1,1,84)    -> (1,84)
拼接为：(1,183372)